#!/usr/bin/env python3
"""
æ–‡å­—åˆ—å¤šè¨€èªåŒ–ç§»è¡Œæ”¯æ´ãƒ„ãƒ¼ãƒ«

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€Flutterãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸæ–‡å­—åˆ—ã‚’
ARBãƒ•ã‚¡ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ã®å¤šè¨€èªåŒ–ã‚·ã‚¹ãƒ†ãƒ ã«ç§»è¡Œã™ã‚‹ãŸã‚ã®ãƒ„ãƒ¼ãƒ«ã§ã™ã€‚

ä½¿ç”¨æ–¹æ³•:
    python3 tools/string_migration.py --scan           # æ–‡å­—åˆ—ã‚’ã‚¹ã‚­ãƒ£ãƒ³
    python3 tools/string_migration.py --extract        # ARBå€™è£œã‚’ç”Ÿæˆ
    python3 tools/string_migration.py --validate       # ç§»è¡ŒçŠ¶æ³ãƒã‚§ãƒƒã‚¯
"""

import re
import os
import json
import argparse
from typing import List, Dict, Set, Tuple
from pathlib import Path

class StringMigrationTool:
    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.lib_dir = self.project_root / "lib"
        self.l10n_dir = self.project_root / "lib" / "l10n"
        self.arb_en = self.l10n_dir / "app_en.arb"
        self.arb_ja = self.l10n_dir / "app_ja.arb"
        
        # æ—¥æœ¬èªæ–‡å­—ã®æ­£è¦è¡¨ç¾
        self.japanese_pattern = re.compile(r'[\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FAF\u3000-\u303F]')
        
        # æ–‡å­—åˆ—ãƒªãƒ†ãƒ©ãƒ«ã®æ­£è¦è¡¨ç¾
        self.string_patterns = [
            re.compile(r"'([^'\\\\]*(\\\\.[^'\\\\]*)*)'"),  # ã‚·ãƒ³ã‚°ãƒ«ã‚¯ã‚©ãƒ¼ãƒˆ
            re.compile(r'"([^"\\\\]*(\\\\.[^"\\\\]*)*)"'),  # ãƒ€ãƒ–ãƒ«ã‚¯ã‚©ãƒ¼ãƒˆ
        ]
        
        # é™¤å¤–ã™ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.exclude_patterns = [
            r'import\s+',
            r'part\s+',
            r'//.*',
            r'/\*.*\*/',
            r'print\s*\(',
            r'debugPrint\s*\(',
            r'assert\s*\(',
            r'throw\s+',
        ]
        
        # é™¤å¤–ã™ã‚‹æ–‡å­—åˆ—
        self.exclude_strings = {
            '', ' ', '\n', '\t', '\r',
            'lib/', 'assets/', 'images/', 'sounds/',
            'http', 'https', 'www', '.com', '.jp',
            'TODO', 'FIXME', 'DEBUG', 'ERROR',
        }
    
    def scan_hardcoded_strings(self) -> Dict[str, List[Dict]]:
        """
        ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸæ–‡å­—åˆ—ã‚’ã‚¹ã‚­ãƒ£ãƒ³ã™ã‚‹
        """
        print("ğŸ” Scanning hardcoded strings...")
        results = {}
        
        for dart_file in self.lib_dir.rglob("*.dart"):
            strings = self._extract_strings_from_file(dart_file)
            if strings:
                results[str(dart_file.relative_to(self.project_root))] = strings
        
        return results
    
    def _extract_strings_from_file(self, file_path: Path) -> List[Dict]:
        """
        ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ–‡å­—åˆ—ã‚’æŠ½å‡ºã™ã‚‹
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except Exception as e:
            print(f"âŒ Error reading {file_path}: {e}")
            return []
        
        strings = []
        lines = content.split('\n')
        
        for line_num, line in enumerate(lines, 1):
            # é™¤å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯
            if any(re.search(pattern, line) for pattern in self.exclude_patterns):
                continue
            
            # æ–‡å­—åˆ—ãƒªãƒ†ãƒ©ãƒ«ã‚’æŠ½å‡º
            for pattern in self.string_patterns:
                for match in pattern.finditer(line):
                    string_content = match.group(1)
                    
                    # é™¤å¤–æ–‡å­—åˆ—ã‚’ã‚¹ã‚­ãƒƒãƒ—
                    if string_content in self.exclude_strings:
                        continue
                    
                    # ç©ºç™½ã®ã¿ã‚’ã‚¹ã‚­ãƒƒãƒ—
                    if not string_content.strip():
                        continue
                    
                    # æŠ€è¡“çš„ãªæ–‡å­—åˆ—ã‚’ã‚¹ã‚­ãƒƒãƒ—
                    if self._is_technical_string(string_content):
                        continue
                    
                    string_info = {
                        'content': string_content,
                        'line': line_num,
                        'column': match.start() + 1,
                        'context': line.strip(),
                        'has_japanese': bool(self.japanese_pattern.search(string_content)),
                        'is_ui_text': self._is_likely_ui_text(string_content, line),
                        'suggested_key': self._suggest_key_name(string_content),
                    }
                    strings.append(string_info)
        
        return strings
    
    def _is_technical_string(self, string_content: str) -> bool:
        """
        æŠ€è¡“çš„ãªæ–‡å­—åˆ—ã‹ã©ã†ã‹ã‚’åˆ¤å®š
        """
        technical_indicators = [
            '/', '\\\\', ':', '.', '_test', '_debug',
            'localhost', '127.0.0.1', 'firebase',
            'ca-app-pub-', 'google.com', 'android',
        ]
        
        lower_content = string_content.lower()
        return any(indicator in lower_content for indicator in technical_indicators)
    
    def _is_likely_ui_text(self, string_content: str, line_context: str) -> bool:
        """
        UI ãƒ†ã‚­ã‚¹ãƒˆã§ã‚ã‚‹å¯èƒ½æ€§ãŒé«˜ã„ã‹ã‚’åˆ¤å®š
        """
        ui_indicators = [
            'Text(', 'title:', 'subtitle:', 'label:', 'hint:',
            'AppBar', 'AlertDialog', 'SnackBar', 'tooltip:',
            'ElevatedButton', 'TextButton', 'IconButton',
        ]
        
        return any(indicator in line_context for indicator in ui_indicators)
    
    def _suggest_key_name(self, string_content: str) -> str:
        """
        æ–‡å­—åˆ—ã‹ã‚‰ã‚­ãƒ¼åã‚’ææ¡ˆ
        """
        # æ—¥æœ¬èªã‹ã‚‰è‹±èªã¸ã®ç°¡å˜ãªãƒãƒƒãƒ”ãƒ³ã‚°
        key_mappings = {
            'ã¯ã˜ã‚ã‚‹': 'buttonStart',
            'ã¤ã¥ãã‹ã‚‰': 'buttonContinue',
            'ã‚ãã³ã‹ãŸ': 'buttonHowToPlay',
            'è¨­å®š': 'settings',
            'é–‰ã˜ã‚‹': 'buttonClose',
            'ã‚­ãƒ£ãƒ³ã‚»ãƒ«': 'buttonCancel',
            'ç¢ºèª': 'buttonConfirm',
            'æˆ»ã‚‹': 'back',
            'ã‚¨ãƒ©ãƒ¼': 'error',
            'æˆåŠŸ': 'success',
        }
        
        if string_content in key_mappings:
            return key_mappings[string_content]
        
        # ä¸€èˆ¬çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰æ¨æ¸¬
        content_lower = string_content.lower()
        
        # ãƒœã‚¿ãƒ³ç³»
        if any(word in content_lower for word in ['button', 'click', 'tap']):
            return f"button{string_content.replace(' ', '').title()}"
        
        # ã‚¨ãƒ©ãƒ¼ç³»
        if any(word in content_lower for word in ['error', 'failed', 'ã‚¨ãƒ©ãƒ¼']):
            return f"error{string_content[:10].replace(' ', '').title()}"
        
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç³»
        if any(word in content_lower for word in ['message', 'msg']):
            return f"message{string_content[:10].replace(' ', '').title()}"
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        clean_content = re.sub(r'[^\w\s]', '', string_content)[:20]
        return f"text{clean_content.replace(' ', '').title()}"
    
    def generate_arb_candidates(self, scan_results: Dict[str, List[Dict]]) -> Dict[str, Dict]:
        """
        ã‚¹ã‚­ãƒ£ãƒ³çµæœã‹ã‚‰ARBå€™è£œã‚’ç”Ÿæˆ
        """
        print("ğŸ“ Generating ARB candidates...")
        
        en_candidates = {}
        ja_candidates = {}
        
        # æ—¢å­˜ã®ARBãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        existing_en = self._load_arb_file(self.arb_en) if self.arb_en.exists() else {}
        existing_ja = self._load_arb_file(self.arb_ja) if self.arb_ja.exists() else {}
        
        # å„ªå…ˆåº¦ä»˜ãã§å‡¦ç†
        all_strings = []
        for file_path, strings in scan_results.items():
            for string_info in strings:
                all_strings.append((file_path, string_info))
        
        # UI ãƒ†ã‚­ã‚¹ãƒˆã‚’å„ªå…ˆã—ã¦ã‚½ãƒ¼ãƒˆ
        all_strings.sort(key=lambda x: (
            not x[1]['is_ui_text'],  # UI ãƒ†ã‚­ã‚¹ãƒˆã‚’å…ˆã«
            not x[1]['has_japanese'],  # æ—¥æœ¬èªæ–‡å­—åˆ—ã‚’å…ˆã«
            x[1]['content']
        ))
        
        processed_contents = set()
        for file_path, string_info in all_strings:
            content = string_info['content']
            
            # é‡è¤‡é™¤å»
            if content in processed_contents:
                continue
            processed_contents.add(content)
            
            # æ—¢ã« ARB ãƒ•ã‚¡ã‚¤ãƒ«ã«å­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            suggested_key = string_info['suggested_key']
            if suggested_key in existing_en:
                continue
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä»˜ãã§ ARB ã‚¨ãƒ³ãƒˆãƒªã‚’ç”Ÿæˆ
            description = self._generate_description(content, string_info)
            
            en_candidates[suggested_key] = content if not string_info['has_japanese'] else "[TRANSLATION_NEEDED]"
            en_candidates[f"@{suggested_key}"] = {
                "description": description,
                "source_file": file_path,
                "source_line": string_info['line']
            }
            
            if string_info['has_japanese']:
                ja_candidates[suggested_key] = content
        
        return {
            'en': en_candidates,
            'ja': ja_candidates
        }
    
    def _load_arb_file(self, file_path: Path) -> Dict:
        """
        ARBãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"âŒ Error loading {file_path}: {e}")
            return {}
    
    def _generate_description(self, content: str, string_info: Dict) -> str:
        """
        æ–‡å­—åˆ—ã®èª¬æ˜ã‚’ç”Ÿæˆ
        """
        if string_info['is_ui_text']:
            if 'button' in string_info['suggested_key'].lower():
                return f"Button label: {content}"
            elif 'error' in string_info['suggested_key'].lower():
                return f"Error message: {content}"
            elif 'title' in string_info['suggested_key'].lower():
                return f"Title text: {content}"
            else:
                return f"UI text: {content}"
        else:
            return f"Text content: {content}"
    
    def validate_migration_status(self) -> Dict:
        """
        ç§»è¡ŒçŠ¶æ³ã‚’æ¤œè¨¼
        """
        print("âœ… Validating migration status...")
        
        # ARB ãƒ•ã‚¡ã‚¤ãƒ«ã®çŠ¶æ³
        arb_status = self._validate_arb_files()
        
        # AppLocalizations ã®ä½¿ç”¨çŠ¶æ³
        usage_status = self._validate_localization_usage()
        
        # æ®‹å­˜ã™ã‚‹ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰æ–‡å­—åˆ—
        remaining_strings = self.scan_hardcoded_strings()
        
        return {
            'arb_files': arb_status,
            'localization_usage': usage_status,
            'remaining_hardcoded': remaining_strings,
            'migration_progress': self._calculate_migration_progress(remaining_strings)
        }
    
    def _validate_arb_files(self) -> Dict:
        """
        ARB ãƒ•ã‚¡ã‚¤ãƒ«ã®å¦¥å½“æ€§ã‚’æ¤œè¨¼
        """
        status = {'en': {}, 'ja': {}}
        
        for lang, file_path in [('en', self.arb_en), ('ja', self.arb_ja)]:
            if not file_path.exists():
                status[lang]['exists'] = False
                continue
            
            status[lang]['exists'] = True
            arb_data = self._load_arb_file(file_path)
            
            # æ–‡å­—åˆ—ã‚¨ãƒ³ãƒˆãƒªã®æ•°ï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿é™¤å¤–ï¼‰
            string_keys = [k for k in arb_data.keys() if not k.startswith('@') and not k.startswith('@@')]
            status[lang]['string_count'] = len(string_keys)
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®å®Œæ•´æ€§ï¼ˆè‹±èªã®ã¿ï¼‰
            if lang == 'en':
                missing_metadata = []
                for key in string_keys:
                    if f"@{key}" not in arb_data:
                        missing_metadata.append(key)
                status[lang]['missing_metadata'] = missing_metadata
        
        return status
    
    def _validate_localization_usage(self) -> Dict:
        """
        AppLocalizations ã®ä½¿ç”¨çŠ¶æ³ã‚’æ¤œè¨¼
        """
        usage_count = 0
        files_with_usage = []
        
        for dart_file in self.lib_dir.rglob("*.dart"):
            try:
                with open(dart_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    
                if 'AppLocalizations.of(context)' in content:
                    usage_count += len(re.findall(r'AppLocalizations\.of\(context\)', content))
                    files_with_usage.append(str(dart_file.relative_to(self.project_root)))
            except Exception:
                continue
        
        return {
            'total_usage_count': usage_count,
            'files_count': len(files_with_usage),
            'files_with_usage': files_with_usage
        }
    
    def _calculate_migration_progress(self, remaining_strings: Dict) -> Dict:
        """
        ç§»è¡Œé€²æ—ã‚’è¨ˆç®—
        """
        total_files = len(list(self.lib_dir.rglob("*.dart")))
        files_with_hardcoded = len(remaining_strings)
        
        total_hardcoded = sum(len(strings) for strings in remaining_strings.values())
        ui_text_count = sum(
            sum(1 for s in strings if s['is_ui_text']) 
            for strings in remaining_strings.values()
        )
        
        return {
            'total_dart_files': total_files,
            'files_with_hardcoded': files_with_hardcoded,
            'total_hardcoded_strings': total_hardcoded,
            'ui_text_remaining': ui_text_count,
            'migration_percentage': max(0, 100 - (files_with_hardcoded / total_files * 100)),
        }
    
    def export_results(self, data: Dict, output_file: str):
        """
        çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«å‡ºåŠ›
        """
        output_path = self.project_root / output_file
        
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            print(f"âœ… Results exported to: {output_path}")
        except Exception as e:
            print(f"âŒ Error exporting results: {e}")
    
    def print_summary(self, data: Dict):
        """
        çµæœã®ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º
        """
        if 'migration_progress' in data:
            # æ¤œè¨¼çµæœã®ã‚µãƒãƒªãƒ¼
            progress = data['migration_progress']
            print(f"\nğŸ“Š Migration Progress Summary:")
            print(f"  Total Dart files: {progress['total_dart_files']}")
            print(f"  Files with hardcoded strings: {progress['files_with_hardcoded']}")
            print(f"  Total hardcoded strings: {progress['total_hardcoded_strings']}")
            print(f"  UI text remaining: {progress['ui_text_remaining']}")
            print(f"  Migration progress: {progress['migration_percentage']:.1f}%")
            
            arb = data['arb_files']
            print(f"\nğŸ“š ARB Files Status:")
            print(f"  English strings: {arb['en'].get('string_count', 0)}")
            print(f"  Japanese strings: {arb['ja'].get('string_count', 0)}")
            print(f"  Missing metadata: {len(arb['en'].get('missing_metadata', []))}")
        
        elif 'en' in data:
            # ARB å€™è£œã®ã‚µãƒãƒªãƒ¼
            print(f"\nğŸ“ ARB Candidates Generated:")
            print(f"  English entries: {len([k for k in data['en'].keys() if not k.startswith('@')])}")
            print(f"  Japanese entries: {len(data['ja'].keys())}")
        
        else:
            # ã‚¹ã‚­ãƒ£ãƒ³çµæœã®ã‚µãƒãƒªãƒ¼
            total_strings = sum(len(strings) for strings in data.values())
            ui_strings = sum(
                sum(1 for s in strings if s['is_ui_text']) 
                for strings in data.values()
            )
            japanese_strings = sum(
                sum(1 for s in strings if s['has_japanese']) 
                for strings in data.values()
            )
            
            print(f"\nğŸ” Scan Results Summary:")
            print(f"  Files with hardcoded strings: {len(data)}")
            print(f"  Total hardcoded strings: {total_strings}")
            print(f"  UI text strings: {ui_strings}")
            print(f"  Japanese strings: {japanese_strings}")


def main():
    parser = argparse.ArgumentParser(description="String migration tool for Flutter i18n")
    parser.add_argument('--scan', action='store_true', help='Scan for hardcoded strings')
    parser.add_argument('--extract', action='store_true', help='Extract ARB candidates')
    parser.add_argument('--validate', action='store_true', help='Validate migration status')
    parser.add_argument('--project-root', default='.', help='Project root directory')
    parser.add_argument('--output', help='Output file for results')
    
    args = parser.parse_args()
    
    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ escape_room ã«è¨­å®š
    if args.project_root == '.':
        current_dir = Path.cwd()
        if current_dir.name == 'escape_room':
            project_root = str(current_dir)
        else:
            project_root = str(current_dir / 'escape_room')
    else:
        project_root = args.project_root
    
    tool = StringMigrationTool(project_root)
    
    if args.scan:
        results = tool.scan_hardcoded_strings()
        tool.print_summary(results)
        if args.output:
            tool.export_results(results, args.output)
    
    elif args.extract:
        # ã¾ãšã‚¹ã‚­ãƒ£ãƒ³ã—ã¦ã‹ã‚‰ ARB å€™è£œã‚’ç”Ÿæˆ
        scan_results = tool.scan_hardcoded_strings()
        arb_candidates = tool.generate_arb_candidates(scan_results)
        tool.print_summary(arb_candidates)
        if args.output:
            tool.export_results(arb_candidates, args.output)
    
    elif args.validate:
        status = tool.validate_migration_status()
        tool.print_summary(status)
        if args.output:
            tool.export_results(status, args.output)
    
    else:
        parser.print_help()


if __name__ == "__main__":
    main()